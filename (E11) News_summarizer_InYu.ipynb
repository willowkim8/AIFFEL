{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noted-mention",
   "metadata": {},
   "source": [
    "**모듈 import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "induced-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aiffel-\n",
      "[nltk_data]     dj35/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-kentucky",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "removable-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hazardous-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22070</th>\n",
       "      <td>There will be obstacles but Arjun will be prep...</td>\n",
       "      <td>Former Indian cricketer Sachin Tendulkar has s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91196</th>\n",
       "      <td>18-year-old becomes first Indian to take pole ...</td>\n",
       "      <td>India's 18-year-old car racer Jehan Daruvala b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53507</th>\n",
       "      <td>Physicists render experiment's magnetic field ...</td>\n",
       "      <td>US-based particle physicists have collaborated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>Japan underpaid Ã¢ÂÂ¹3,480cr in unemployment ...</td>\n",
       "      <td>Japan failed to pay a total of 53.7 billion ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90055</th>\n",
       "      <td>US police offer to test meth for 'deadly gluten'</td>\n",
       "      <td>California police officers have offered to tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21403</th>\n",
       "      <td>350 US newspapers plan editorials over Trump's...</td>\n",
       "      <td>Nearly 350 US newspapers will on Thursday publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87582</th>\n",
       "      <td>Salman to launch brother-in-law in film with K...</td>\n",
       "      <td>As per reports, Salman Khan plans to launch hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18228</th>\n",
       "      <td>Mutual fund asset base crosses Ã¢ÂÂ¹25 lakh c...</td>\n",
       "      <td>The assets under management of India's mutual ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10118</th>\n",
       "      <td>Apple design head to create ring made entirely...</td>\n",
       "      <td>Jony Ive, Apple's Chief Design Officer, has cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I only cried at my 'bidaai' as I felt peer pr...</td>\n",
       "      <td>Reliance Industries' Chairman Mukesh Ambani's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "22070  There will be obstacles but Arjun will be prep...   \n",
       "91196  18-year-old becomes first Indian to take pole ...   \n",
       "53507  Physicists render experiment's magnetic field ...   \n",
       "2387   Japan underpaid Ã¢ÂÂ¹3,480cr in unemployment ...   \n",
       "90055   US police offer to test meth for 'deadly gluten'   \n",
       "21403  350 US newspapers plan editorials over Trump's...   \n",
       "87582  Salman to launch brother-in-law in film with K...   \n",
       "18228  Mutual fund asset base crosses Ã¢ÂÂ¹25 lakh c...   \n",
       "10118  Apple design head to create ring made entirely...   \n",
       "14      I only cried at my 'bidaai' as I felt peer pr...   \n",
       "\n",
       "                                                    text  \n",
       "22070  Former Indian cricketer Sachin Tendulkar has s...  \n",
       "91196  India's 18-year-old car racer Jehan Daruvala b...  \n",
       "53507  US-based particle physicists have collaborated...  \n",
       "2387   Japan failed to pay a total of 53.7 billion ye...  \n",
       "90055  California police officers have offered to tes...  \n",
       "21403  Nearly 350 US newspapers will on Thursday publ...  \n",
       "87582  As per reports, Salman Khan plans to launch hi...  \n",
       "18228  The assets under management of India's mutual ...  \n",
       "10118  Jony Ive, Apple's Chief Design Officer, has cr...  \n",
       "14     Reliance Industries' Chairman Mukesh Ambani's ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#랜덤한 10개 샘플 출력\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "foreign-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rahat Fateh Ali Khan denies getting notice for...</td>\n",
       "      <td>Pakistani singer Rahat Fateh Ali Khan has deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India get all out for 92, their lowest ODI tot...</td>\n",
       "      <td>India recorded their lowest ODI total in New Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Govt directs Alok Verma to join work 1 day bef...</td>\n",
       "      <td>Weeks after ex-CBI Director Alok Verma told th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Called PM Modi 'sir' 10 times to satisfy his e...</td>\n",
       "      <td>Andhra Pradesh CM N Chandrababu Naidu has said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cong wins Ramgarh bypoll in Rajasthan, takes t...</td>\n",
       "      <td>Congress candidate Shafia Zubair won the Ramga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "5  Rahat Fateh Ali Khan denies getting notice for...   \n",
       "6  India get all out for 92, their lowest ODI tot...   \n",
       "7  Govt directs Alok Verma to join work 1 day bef...   \n",
       "8  Called PM Modi 'sir' 10 times to satisfy his e...   \n",
       "9  Cong wins Ramgarh bypoll in Rajasthan, takes t...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  \n",
       "5  Pakistani singer Rahat Fateh Ali Khan has deni...  \n",
       "6  India recorded their lowest ODI total in New Z...  \n",
       "7  Weeks after ex-CBI Director Alok Verma told th...  \n",
       "8  Andhra Pradesh CM N Chandrababu Naidu has said...  \n",
       "9  Congress candidate Shafia Zubair won the Ramga...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-population",
   "metadata": {},
   "source": [
    "이 데이터는 기사의 본문에 해당되는 headlines와 test 두 가지 열로 구성되어져 있습니다.  \n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있어요. 추출적 요약을 하는 경우에는 오직 text열만을 사용하세요.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-pressing",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "motivated-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98401\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-thompson",
   "metadata": {},
   "source": [
    "## 중복 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smooth-marijuana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n",
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# 중복 확인 \n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-complex",
   "metadata": {},
   "source": [
    "당연히 헤드라인이 중복 샘플이 더 많다. 헤드라인은 동일할 수 있다.  \n",
    "텍스트가 중복인것을 제거하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# 임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거\n",
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-cookbook",
   "metadata": {},
   "source": [
    "## Null 값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "gothic-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-disco",
   "metadata": {},
   "source": [
    "Null값이 없음  \n",
    "## 텍스트 정규화와 불용어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-childhood",
   "metadata": {},
   "source": [
    "기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법  \n",
    "이러한 방법론을 텍스트 처리에서는 텍스트 정규화(text normalization)라 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "satisfactory-making",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-nerve",
   "metadata": {},
   "source": [
    "자연어 처리할 때 실질적으로 도움이 되지 않는 단어를 불용어(stopwords)라고 한다.  \n",
    "NLTK에서 제공하는 불용어 리스트를 참조해서 불용어를 제거해보자  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "third-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-scanner",
   "metadata": {},
   "source": [
    "이 179개의 불용어를 제거하고\n",
    "모든 문자를 소문자로 만들고  \n",
    "섞여있는 html 태그를 제거하고  \n",
    "정규식 표현을 통해 각종 특수문자를 제거  \n",
    "\n",
    "그런데 헤드라인은 상대적으로 길이가 짧기 때문에 불용어를 살려두겠다  \n",
    "불용어가 살아 있어야 추상적으로 요약한 문장이 자연스럽기 때문에\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "monthly-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-china",
   "metadata": {},
   "source": [
    "전처리 전, 후의 결과를 확인하기 위해서 임의의 text와 summary를 만들어 함수를 호출해볼까요.\n",
    "혹시 아래 코드가 오류가 난다면 parser가 설치되어있지 않은 것이니, lxml을 설치해주세요.\n",
    "```\n",
    "$ pip install lxml```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sound-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 함수 확인해보기 \n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beneficial-credit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       " 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years',\n",
       " 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-european",
   "metadata": {},
   "source": [
    "이제 Summary에 대해서 전처리 함수를 호출해줄 때는, 불용어 제거를 수행하지 않는다는 의미에서 두번째 인자로 False를 넣어줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "endangered-flesh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upgrad learner switches to career in ml al with salary hike',\n",
       " 'delhi techie wins free food from swiggy for one year on cred',\n",
       " 'new zealand end rohit sharma led india match winning streak',\n",
       " 'aegon life iterm insurance plan helps customers save tax',\n",
       " 'have known hirani for yrs what if metoo claims are not true sonam']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_head = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_head.append(preprocess_sentence(s, False))\n",
    "\n",
    "clean_head[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-stuff",
   "metadata": {},
   "source": [
    "## 다시 Null값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "endangered-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_head\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fantastic-principle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-riverside",
   "metadata": {},
   "source": [
    "Null 값  음슴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-wings",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (2) 훈련데이터와 테스트데이터 나누기\n",
    "## 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "coral-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "제목의 최소 길이 : 1\n",
      "제목의 최대 길이 : 16\n",
      "제목의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb/klEQVR4nO3df3xddZ3n8dc7oaYUK6U2sFWscVd+xHT5IRl1tsxghdI68qDdfVClD3ErRGpgjM7CjAHycJXHY9uxu+LoVB/NlGm3faxsgGVEuj4cW9oG3DIMGhCUNigMI1DBNtAWmTKtJf3sH/e03oakaW5uzjm59/18PO7j3vM9997z6Y+Td77nfM/3KCIwMzPLm5qsCzAzMxuMA8rMzHLJAWVmZrnkgDIzs1xyQJmZWS45oMzMLJccUCmQ9CtJl4zxNhokhaQTkuUHJH0mef1JSRvHcvtmZuXmgKoCEXFHRFyadR1mWZL0L0WPQ5L+tWj5kyV834cl7RiLWq3ghKwLMDNLQ0S89fBrSb8CPhMRm7KryIbjHlR6zpP0M0mvSrpL0kQASZdJelzSXkn/IOmcwx+QdJOkf5L0mqTtkv5j0bpaSV+T9LKkZ4GPDbVhSZ+WtLVoOSS1Snpa0h5J35akovXXSOpN1m2Q9O6kXZL+StKu5M/xM0kzy/z3ZJYqSTVF+9orku6WNDVZt1LSPUXvXS5ps6STgL8H3lHUC3tHVn+GSuWASs/HgXnAe4BzgE9Lej+wBvgs8Hbgb4D1kuqSz/wT8EfAycCtwHckTU/WXQtcBpwPNANXjLCey4A/AM5NapsLIGkBcAvwn4B64P8BXclnLgX+GDgTmAJ8AnhlhNs1y5vPAwuAi4B3AHuAbyfrbgTOSX7J+yOgBVgcEfuAjwIvRsRbk8eL6Zde2RxQ6fnriHgxInYD/xc4j0LI/E1EPBIR/RGxDjgAfAggIv5P8plDEXEX8DTwgeT7Pg58IyJeSL7zL0dYz1cjYm9EPA90J/VAISz/MiJ6I+INYBmF3t+7gYPAZOBsQMl7XirlL8MsRz4LdETEjog4AHwFuELSCRHxOnAV8HXgO0BbRPi8U0ocUOn5TdHr14G3Au8GbkwO7+2VtBd4F4Xf4pD0n4sO/+0FZgLTku94B/BC0Xc+V4Z6SGr6ZtE2dwMC3hkRW4BvUfjtcqekVZLeNsLtmuXNu4F7i/7P9wL9wGkAEfFj4FkK+8HdWRVZjRxQ2XoBWBoRU4oekyKiK+mx3A58Dnh7REwBnqSwkwC8RCHMDptRxpo+O6CmEyPiHwAi4q8j4gKgicKhvr8o03bNsvIC8NEB/+cnRsSvAST9KVAHvAh8sehzvhXEGHNAZet2oFXSB5MBCCdJ+pikycBJFHaAPgBJV1PoQR12N/B5SadLOgW4qUw1dQI3S2pKtnuypIXJ6z9Iap0A7AP2U/hN02w86wSWFg0Gqpc0P3l9JvDfKBzm+xTwRUnnJZ/bCbxd0snpl1wdHFAZiogeCuehvkXhxOwzwKeTdduB24CHKewI/x54qOjjtwMbgCeAx4Dvlqmme4HlwJ2Sfkuh1/bRZPXbku3uoXBI8RXga+XYrlmGvgmsBzZKeg34R+CDyUXv3wGWR8QTEfE0hQFE/0tSXUQ8RWEA0bPJ4UGP4isz+YaFZmaWR+5BmZlZLjmgzMwslxxQZmaWSw4oMzPLpVQni502bVo0NDSkuUmzMfPoo4++HBH1WWzb+5JVkqH2pVQDqqGhgZ6enjQ3aTZmJI109o6y8b5klWSofcmH+MzMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcskBZWZmuTRsQElaI2mXpCcHtLdJ+oWkbZL++9iVaMdr7ty51NTUIImamhrmzp2bdUk2gKQpku6R9JSkXkl/KGmqpPslPZ08n5J1ndWuq6uLmTNnUltby8yZM+nq6sq6pKp0PD2otcC84gZJs4H5wDkR0YRvuZC5uXPnsnHjRlpbW9m7dy+tra1s3LjRIZU/3wR+GBFnA+dSuHvrTcDmiDgD2Ez57u1lJejq6qKjo4MVK1awf/9+VqxYQUdHh0MqCxEx7ANoAJ4sWr4buOR4Plv8uOCCC8LGhqS47rrrjmq77rrrQlJGFVU+oCdG8P+fwv20/pnkNjdF7b8ApievpwO/GO67vC+NnaamptiyZctRbVu2bImmpqaMKqp8Q+1Lx3U/KEkNwPcjYmay/DhwH4We1X7gzyPiJ0N8dgmwBGDGjBkXPPdcZhffVzRJ7N27l5NP/v3NPV999VWmTJnC8fwb28hJejQimkfw/vOAVcB2Cr2nR4EvAL+OiClF79sTEW86zOd9KR21tbXs37+fCRMmHGk7ePAgEydOpL/fN5AeC0PtS6UOkjgBOAX4EPAXwN2SNNgbI2JVRDRHRHN9fSbTllUFSdx8881Htd18880M8c9i2TgBeD+wMiLOB/YxgsN53pfS0djYyNatW49q27p1K42NjRlVVL1KDagdwHeT3tmPgUPAtPKVZSM1Z84cVq5cyfXXX8+rr77K9ddfz8qVK5kzZ07Wpdnv7QB2RMQjyfI9FAJrp6TpAMnzrozqM6Cjo4OWlha6u7s5ePAg3d3dtLS00NHRkXVpVafUyWK/B3wEeEDSmcBbgJfLVZSN3IYNG5g7dy6dnZ2sXLkSSVx66aVs2LAh69IsERG/kfSCpLMi4hfAxRQO920HFgNfTZ7vy7DMqrdo0SIA2tra6O3tpbGxkaVLlx5pt/QMG1CSuoAPA9Mk7QC+DKwB1iRDz38HLA6f6Micw2hcaAPukPQW4FngagpHMu6W1AI8DyzMsD6jEFIOpOwNG1ARMdS/0lVlrsWs4kXE48BgAysuTrkUs9zzTBJmZpZLDigzM8slB5SZmeWSA8rMzHLJAWVmZrlU6nVQlkODzRrh0f9mNl65B1UhisPpzjvvHLTdzGw8cUBVmIjgE5/4hHtOZjbuOaAqSHHPabBlM7PxxAFVQa688spjLpvZ8fEddfPBAVVhJHHXXXf53JNZiXxH3fxwQFWI4nNOxT0nn4syG5mlS5eyevVqZs+ezYQJE5g9ezarV69m6dKlWZdWdTzMvII4jMxGr7e3lwsvvPCotgsvvJDe3t6MKqpe7kGZmRVpbGzk1ltvPeoc1K233uo76mbAAWVmVmT27NksX76ca665htdee41rrrmG5cuXM3v27KxLqzoOKDOzIt3d3bS3t7NmzRomT57MmjVraG9vp7u7O+vSqo7PQZmZFent7WX69Ols376diGD79u1Mnz7d56Ay4B6UmVmRE088kU2bNtHa2srevXtpbW1l06ZNnHjiiVmXVnUcUGZmRfbt28fkyZNZuHAhkyZNYuHChUyePJl9+/ZlXVrVGTagJK2RtEvSk4Os+3NJIWna2JRnIyHpTQ8zG7nbbruNtrY2Jk6cSFtbG7fddlvWJVWl4+lBrQXmDWyU9C5gDvB8mWuyEgwVRg4ps5GRRHt7O9u2bePQoUNs27aN9vZ270sZGDagIuJHwO5BVv0V8EXAV4fmSEQceZjZyE2aNIk9e/bQ0NDAM888Q0NDA3v27GHSpElZl1Z1ShrFJ+ly4NcR8cRwv1VIWgIsAZgxY0YpmzMzS82+ffuYNm0azz33HO9973uRxLRp03j55ZezLq3qjHiQhKRJQAfwX4/n/RGxKiKaI6K5vr5+pJszM0tdfX39kaMQEYF/dmWjlFF8/w54D/CEpF8BpwOPSfo35SzMSuMBEmaj19vby+WXX05fXx+XX365r4HKyIgP8UXEz4FTDy8nIdUcEe7/ZigiBg0ln4sys/Fq2ICS1AV8GJgmaQfw5YhYPdaF2cg5jMzK4+yzz2b9+vVHDu2dffbZPPXUUxlXVX2GDaiIWDTM+oayVWNW4ZIjDq8B/cAbEdEsaSpwF9AA/Ar4eETsyapG401h5HDKhmeSMEvf7Ig4LyKak+WbgM0RcQawOVm2HLjnnnuyLqGqOaDMsjcfWJe8XgcsyK4UK3bFFVdkXUJVc0CZpSuAjZIeTa4RBDgtIl4CSJ5PHeyDkpZI6pHU09fXl1K51WnTpk1HXfS+adOmrEuqSr7dhlm6ZkXEi5JOBe6XdNwnNyJiFbAKoLm52SNixtAll1ySdQmGe1BmqYqIF5PnXcC9wAeAnZKmAyTPu7Kr0IotX7486xKqmgPKLCWSTpI0+fBr4FLgSWA9sDh522LgvmwqtIHa29uzLqGq+RCfWXpOA+5NLqg+AfjfEfFDST8B7pbUQuHuAAszrNEsN9yDMktJRDwbEecmj6aIWJq0vxIRF0fEGcnzYHcPsAx86UtfyrqEquaAGqcGuznh8T7MbHg1NTVcdNFF1NT4x2RWfIhvnDrWtEaSPO2R2SgdOnTIo/ky5l8NzMwslxxQZmaWSw4oMzPLJQeUmZnlkgPKzMxyyQFlZjaE0047LesSqpoDysxsCDt37sy6hKrm66DMzAZRfC2hL3DPhgPKzGwQDqXsDXuIT9IaSbskPVnU9j8kPSXpZ5LulTRlTKs0M0vJULOweHaW9B3POai1wLwBbfcDMyPiHOCXwM1lrsvMLBXHO1+l57RM37ABFRE/AnYPaNsYEW8ki/8InD4GtZmZjbniW7sPfBxrvY29coziuwb4+zJ8j5mZ2RGjCihJHcAbwB3HeM8SST2Sevr6+kazOTMzqyIlB5SkxcBlwCfjGP3diFgVEc0R0VxfX1/q5szMrMqUNMxc0jygHbgoIl4vb0lmZmbHN8y8C3gYOEvSDkktwLeAycD9kh6X1DnGdZqZWZUZtgcVEYsGaV49BrWYmZkd4bn4zMwslxxQZmaWSw4oMzPLJQeUmZnlkgPKzMxyyQFlZma55IAyM7NcckCZpUhSraSfSvp+sjxV0v2Snk6eT8m6RrO8cECZpesLQG/R8k3A5og4A9icLJsZDiiz1Eg6HfgY8LdFzfOBdcnrdcCClMsyyy0HlFl6vgF8EThU1HZaRLwEkDyfOtSHfesaqzYOKLMUSLoM2BURj5b6Hb51jVWbkm63YWYjNgu4XNKfABOBt0n6DrBT0vSIeEnSdGBXplWa5Yh7UGYpiIibI+L0iGgArgS2RMRVwHpgcfK2xcB9GZVoljsOKLNsfRWYI+lpYE6ybGb4EJ9Z6iLiAeCB5PUrwMVZ1mOWV+5BmZlZLjmgzKziTZ06FUkjfgAj/szUqVMz/tNWDh/iM7OKt2fPHiIilW0dDjYbPfegzMwsl4YNKElrJO2S9GRRmye4NDOzMXU8Pai1wLwBbZ7g0szMxtSwARURPwJ2D2j2BJdmZjamSj0H5QkuU+CRR2ZWzcZ8FF9ErAJWATQ3N6czjKZCeOSRmVWzUntQO5OJLfEEl2ZmNhZKDShPcGlmZmPqeIaZdwEPA2dJ2iGpBU9waWZmY2zYc1ARsWiIVZ7g0szGhfjy2+ArJ6e3LSsLT3VkZhVPt/421QFH8ZVUNlXxPNWRmZnlkgPKzMxyyQFlZma55IAyM7NcckCZmVkueRSfmVWFtKbzOuUU332oXBxQZlbxSh1iLim14en2Zg6oHPPFhWZWzRxQOeaLC82smnmQhJmZ5ZIDyszMcskBZWZmueSAMjOzXHJAmaVE0kRJP5b0hKRtkm5N2qdKul/S08mzL6QxwwFllqYDwEci4lzgPGCepA8BNwGbI+IMYHOybFb1HFBmKYmCf0kWJySPAOYD65L2dcCC9Kszyx8HlFmKJNVKehzYBdwfEY8Ap0XESwDJ86lDfHaJpB5JPX19fanVbJYVB5RZiiKiPyLOA04HPiBp5gg+uyoimiOiub6+fsxqNMuLUQWUpP+SnOx9UlKXpInlKsyskkXEXuABYB6wU9J0gOR5V3aVmeVHyQEl6Z3A54HmiJgJ1AJXlqsws0ojqV7SlOT1icAlwFPAemBx8rbFwH2ZFGiWM6Odi+8E4ERJB4FJwIujL8msYk0H1kmqpfDL4d0R8X1JDwN3S2oBngcWZlmkWV6UHFAR8WtJX6OwQ/0rsDEiNg58n6QlwBKAGTNmlLq5quV72FSOiPgZcP4g7a8AF6dfkVm+jeYQ3ykUhse+B3gHcJKkqwa+zyd2SxcRJT1K+ezu3bsz/tOamR1tNIMkLgH+OSL6IuIg8F3gP5SnLDMzq3ajCajngQ9JmqTCcaiLgd7ylGVmZtWu5IBKLjC8B3gM+HnyXavKVJeZmVW5UY3ii4gvA18uUy1mZmZHeCYJMzPLJQeUmZnlkgPKzMxyabQzSZiZjWvDXQw/1PrD1xza2HFAmVlVGyxoBgslB1L6fIjPzKzIUD2mtKYds99zD8rMbBDFPSaHUzYcUGZmg3AoZc+H+MzMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcskBZWZmueSAMjMbYP78+UTEkcf8+fOzLqkq+TooM7MB7rvvPl8HlQPuQZmZDeHcc8/NuoSq5oAyMxvCE088kXUJVc0BZWZmuTSqgJI0RdI9kp6S1CvpD8tVmJlZlmpra3nggQeora3NupSqNdpBEt8EfhgRV0h6CzCpDDWZmWWuv7+fl19+mf7+/qxLqVolB5SktwF/DHwaICJ+B/yuPGWZmWXviiuuyLqEqjaaQ3z/FugD/qekn0r6W0knDXyTpCWSeiT19PX1jWJzZuObpHdJ6k4Oh2+T9IWkfaqk+yU9nTyfknWtZnkwmoA6AXg/sDIizgf2ATcNfFNErIqI5ohorq+vH8XmzMa9N4AbI6IR+BDwp5LeR2G/2RwRZwCbGWQ/smx873vfy7qEqjaagNoB7IiIR5LleygElpkNIiJeiojHktevAb3AO4H5wLrkbeuABZkUaG+yYMGCrEuoaiUHVET8BnhB0llJ08XA9rJUZVbhJDUA5wOPAKdFxEtQCDHg1CE+48PlKbn66qupq6sDoK6ujquvvjrjiqrTaK+DagPukPQz4Dxg2agrMqtwkt4K/B3wZxHx2+P9nA+Xp2ft2rUsW7aMffv2sWzZMtauXZt1SVVpVAEVEY8nO8w5EbEgIvaUqzCzSiRpAoVwuiMivps075Q0PVk/HdiVVX0GkogIHnzwQV5//XUefPBBIsJz82XAM0mYpUSFn3Crgd6I+HrRqvXA4uT1YuC+tGuz34sImpqaWL9+PfX19axfv56mpiYiIuvSqo5nMzdLzyzgU8DPJT2etN0CfBW4W1IL8DywMJvyDArnnKZMmUJdXR0HDhw4atnS5R6UWUoiYmtEKDkkfl7y+EFEvBIRF0fEGcnz7qxrrWZnnnkmDz30EHPnzqWvr4+5c+fy0EMPceaZZ2ZdWtVxD8rMrMgvf/lLZs2axYYNG6ivr6euro5Zs2bR09OTdWlVxwFlZlbkwIEDbNy4kUmTfj+16Ouvv85JJ71pohwbYz7EZ2ZWpK6ujs7OzqPaOjs7fQ4qA+5BmZkVufbaa2lvbwegtbWVzs5O2tvbaW1tzbiy6uOAMjMrsmLFCgBuueUWbrzxRurq6mhtbT3SbulxQJmZDbBixQoHUg44oMap4a5qP9Z6X3BoZuOBA2qccsiYWaXzKD4zM8slB5SZmeWSA8rMzHLJAWVmZrnkgDIzs1xyQJmZWS45oMzMLJccUGZmlksOKDMzy6VRB5SkWkk/lfT9chRkpZP0poeZ2XhVjh7UF4DeMnyPjcLhMKqpqWHTpk3U1NQc1W5mNt6Mai4+SacDHwOWAjeUpSIrWU1NDf39/QD09/dTW1vLoUOHMq7KzKw0o+1BfQP4IjDkT0FJSyT1SOrp6+sb5ebsWDZu3HjMZTOz8aTkgJJ0GbArIh491vsiYlVENEdEc319fambs+Nw6aWXHnPZzGw8GU0PahZwuaRfAXcCH5H0nbJUZSU5dOgQtbW1bN682Yf3zGzcKzmgIuLmiDg9IhqAK4EtEXFV2SqzETl8f6hDhw5xySWXHAkn3zfKzMYr37CwgjiMzKySlCWgIuIB4IFyfJeZmRl4JgkzM8spB5RZSiStkbRL0pNFbVMl3S/p6eT5lCxrNMsTB5RZetYC8wa03QRsjogzgM3JspnhgDJLTUT8CNg9oHk+sC55vQ5YkGZNZnnmgDLL1mkR8RJA8nzqUG/0rCxWbRxQFaStrY2JEyciiYkTJ9LW1pZ1SVZGnpXFqo0DqkK0tbXR2dnJsmXL2LdvH8uWLaOzs9MhlX87JU0HSJ53ZVyPWW44oCrE7bffzvLly7nhhhuYNGkSN9xwA8uXL+f222/PujQ7tvXA4uT1YuC+DGsxyxUHVIU4cOAAra2tR7W1trZy4MCBjCqygSR1AQ8DZ0naIakF+CowR9LTwJxk2cxwQFWMuro6Ojs7j2rr7Oykrq4uo4psoIhYFBHTI2JCMo/l6oh4JSIujogzkueBo/zMqpbn4qsQ1157Le3t7UCh59TZ2Ul7e/ubelVmZuOFA6pCrFixAoBbbrmFG2+8kbq6OlpbW4+0m5mNNw6oCrJixQoHkplVDJ+DMjOzXHJAmZlZLjmgzMwslxxQZmaWSw4oMzPLJQeUmZnlUskBJeldkrol9UraJukL5SzMzMyq22iug3oDuDEiHpM0GXhU0v0Rsb1MtZmZWRUruQcVES9FxGPJ69eAXuCd5SrMzMyqW1nOQUlqAM4HHhlkne8CamZmIzbqgJL0VuDvgD+LiN8OXO+7gJqZWSlGFVCSJlAIpzsi4rvlKcnMzGx0o/gErAZ6I+Lr5SvJzMxsdD2oWcCngI9Iejx5/EmZ6jIzsypX8jDziNgKqIy1mJmZHeGZJMzMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcskBVUG6urqYOXMmtbW1zJw5k66urqxLMhuXvC/lw2hmM7cc6erqoqOjg9WrV3PhhReydetWWlpaAFi0aFHG1ZmNH96XciQiUntccMEFYWOjqakptmzZclTbli1boqmpKaOKKh/QEynuP+F9KRXel9I31L6kwrp0NDc3R09PT2rbqya1tbXs37+fCRMmHGk7ePAgEydOpL+/P8PKKpekRyOiOYtte18aO96X0jfUvuRzUBWisbGRrVu3HtW2detWGhsbM6rIRkLSPEm/kPSMpJuyrqeaeV/KDwdUhejo6KClpYXu7m4OHjxId3c3LS0tdHR0ZF2aDUNSLfBt4KPA+4BFkt6XbVXVy/tSfniQRIU4fPK2ra2N3t5eGhsbWbp0qU/qjg8fAJ6JiGcBJN0JzAe2Z1pVlfK+lB8+B2VWonKdg5J0BTAvIj6TLH8K+GBEfG7A+5YASwBmzJhxwXPPPTfaTZvlgs9BmeXXYHcFeNNvjuG7U1uVcUCZZW8H8K6i5dOBFzOqxSw3HFBm2fsJcIak90h6C3AlsD7jmswy50ESZhmLiDckfQ7YANQCayJiW8ZlmWXOAWWWAxHxA+AHWddhlic+xGdmZrmU6jBzSX2Ax8aOvWnAy1kXUQXeHRGZDKfzvpQa70vpGHRfSjWgLB2SerKaI86sknhfypYP8ZmZWS45oMzMLJccUJVpVdYFmFUI70sZ8jkoMzPLJfegzMwslxxQZmaWSw6oCiJpjaRdkp7Muhaz8cz7Uj44oCrLWmBe1kWYVYC1eF/KnAOqgkTEj4DdWddhNt55X8oHB5SZmeWSA8rMzHLJAWVmZrnkgDIzs1xyQFUQSV3Aw8BZknZIasm6JrPxyPtSPniqIzMzyyX3oMzMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcskBZWZmueSAMjOzXPr/9krPdibu2PEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "head_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('제목의 최소 길이 : {}'.format(np.min(head_len)))\n",
    "print('제목의 최대 길이 : {}'.format(np.max(head_len)))\n",
    "print('제목의 평균 길이 : {}'.format(np.mean(head_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(head_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(head_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-headset",
   "metadata": {},
   "source": [
    "결과로부터 Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-auditor",
   "metadata": {},
   "source": [
    "이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하는 편이 객관적으로 길이를 결정하는데 도움이 될거에요. 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "familiar-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len 이하 data가 몇 % 인지\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "noble-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 41 이하인 샘플의 비율: 0.9549613664091094\n",
      "전체 샘플 중 길이가 11 이하인 샘플의 비율: 0.9449877999186661\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 41\n",
    "head_max_len = 11\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(head_max_len, data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-unemployment",
   "metadata": {},
   "source": [
    "## 시작 토큰과 종료 토큰 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-windsor",
   "metadata": {},
   "source": [
    "디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고, 종료 토큰을 예측한 순간에 문장 생성을 멈추는 것  \n",
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있어요.  \n",
    "이번 실습에서는 시작 토큰은 'sostoken', 종료 토큰은 'eostoken'이라 임의로 명명하고 앞, 뒤로 추가할거에요. 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input, 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target이라고 이름을 정했어요. 두 개의 문장 모두 Summary 열로부터 만들거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "seventh-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-lindsay",
   "metadata": {},
   "source": [
    "인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장해줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "combined-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-makeup",
   "metadata": {},
   "source": [
    "## 훈련 데이터와 테스트 데이터를 직접 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-romantic",
   "metadata": {},
   "source": [
    "random하게 숫자를 붙인 후 정렬하면 data를 섞을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "floppy-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98360,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "impossible-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96406 52733 78776 ...  9867 49921 20126]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-medication",
   "metadata": {},
   "source": [
    "섞기 전 샘플도 저장을 해놓시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "maritime-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_encoder_input = encoder_input\n",
    "org_decoder_input = decoder_input\n",
    "org_decoder_target = decoder_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-journey",
   "metadata": {},
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해주면 잘 섞인 샘플이 되겠죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "rotary-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-peeing",
   "metadata": {},
   "source": [
    "이렇게 섞인 데이터는 8:2로 훈련:테스트로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "figured-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19672\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "undefined-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-concert",
   "metadata": {},
   "source": [
    "## 단어 집합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-secretary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "innocent-emperor",
   "metadata": {},
   "source": [
    "정수 인코딩 전에 각 단어에 고유한 정수를 맵핑하는 작업이 필요  \n",
    "encoder_input_train에 대해서 단어 집합을 만들기  \n",
    "Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "competent-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-evanescence",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었어요. 현재 생성된 단어 집합은 src_tokenizer.word_index에 저장되어있어요. 그런데 우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, 빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행하려고 해요.\n",
    "  \n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해볼게요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "palestinian-feeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69689\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47556\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22133\n",
      "단어 집합에서 희귀 단어의 비율: 68.24032487193101\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.496908676961541\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-intranet",
   "metadata": {},
   "source": [
    "등장 빈도가 6회 이하인 단어가 무려 70%이지만  \n",
    "등장 빈도는 3.5% 정도로 작기 때문에 과감하게 훈련데이터에서 제거한다  \n",
    "위에서 이를 제외한 단어수가 2만개 정도이기 때문에   \n",
    "단어 집합을 2만개에 맞춰 보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "virgin-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-spotlight",
   "metadata": {},
   "source": [
    "texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행해요. 현재 단어 집합의 크기를 20,000으로 제한했으니까 이제 20,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않아요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ceramic-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1409, 140, 289, 7352, 140, 203, 144, 387, 140, 116, 272, 1409, 2838, 2076, 1533, 4643, 600, 600, 2057, 7352, 534, 370, 554, 144, 7352, 534, 1409, 92, 1744, 5071, 2354, 2255, 961], [403, 70, 1403, 475, 30, 1841, 403, 15, 1197, 5509, 1703, 191, 1326, 15, 1626, 3403, 11541, 17, 1326, 132, 1841, 7455, 1, 1403, 50, 36, 256, 174, 1704, 3956, 3833], [3815, 1305, 806, 475, 4774, 8712, 9009, 549, 1137, 105, 1868, 718, 1883, 219, 549, 42, 579, 3165, 4090, 249, 1251, 1859, 8712, 1868, 896, 14776, 24, 752, 2629, 12585, 18400, 1137, 612, 4090, 249]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-spectacular",
   "metadata": {},
   "source": [
    "이제 더 이상 텍스트 데이터가 아니라 정수가 나오고 있어요.  \n",
    "  \n",
    "Summary 데이터에 대해서도 동일한 작업을 수행할게요. 케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산해요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "suspended-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fatty-palmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30062\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 20526\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9536\n",
      "단어 집합에서 희귀 단어의 비율: 68.27889029339366\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.301766679826293\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "charged-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 151, 247, 679, 2981, 1413, 9, 89, 205, 4, 83], [1, 194, 1583, 315, 38, 6, 621, 1084, 110, 1634], [1, 3487, 315, 3918, 904, 5, 326, 2633], [1, 2197, 254, 398, 739, 2407, 111], [1, 718, 782, 3, 1315, 26, 570, 1060, 5, 35, 12]]\n",
      "target\n",
      "decoder  [[151, 247, 679, 2981, 1413, 9, 89, 205, 4, 83, 2], [194, 1583, 315, 38, 6, 621, 1084, 110, 1634, 2], [3487, 315, 3918, 904, 5, 326, 2633, 2], [2197, 254, 398, 739, 2407, 111, 2], [718, 782, 3, 1315, 26, 570, 1060, 5, 35, 12, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 9000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-builder",
   "metadata": {},
   "source": [
    "등장 빈도가 6회 미만인 단어를 제외하고 났더니 약 9000개여서 tar_vocab을 9000개로 맞추고  \n",
    "확인했더니  \n",
    "decoder input 앞에는 1이 있고  \n",
    "decoder target 뒤에는 2가 있다.    \n",
    "\n",
    "\n",
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있어요. 이 현상은 길이가 상대적으로 길었던 원문(Text)의 경우에는 문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(Summary)의 경우에는 이 현상이 굉장히 두드러졌을 가능성이 높겠죠.  \n",
    "  \n",
    "요약문에서 길이가 0이 된 샘플들의 인덱스를 받아와볼게요. 여기서 주의할 점은 요약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제 되지 않아요. 그래서 이제 길이가 0이 된 요약문의 **실제길이는 1**로 나올거에요.   \n",
    "길이 0이 된 decoder_input에는 sostoken, decoder_target에는 eostoken만 남아 있을테니까요.  \n",
    "  \n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장해볼게요. 이 샘플들은 모두 삭제할거에요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fifty-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-creator",
   "metadata": {},
   "source": [
    "## 패딩하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-floor",
   "metadata": {},
   "source": [
    "이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업  \n",
    "아까 정해 두었던 길이 = 41에 맞춰 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "removed-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_max_len 와 summary_max_len 에 맞춰서\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = head_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = head_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = head_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = head_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-mailing",
   "metadata": {},
   "source": [
    "## 함수형 API를 이용해서 인코더를 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "advance-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# warning뜬다\n",
    "# WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. \n",
    "# It will use generic GPU kernel as fallback when running on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-butter",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의했어요. hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터에요. 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴론의 갯수라고 이해하면 돼요. 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니에요.  \n",
    "  \n",
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있죠. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?  \n",
    "  \n",
    "## 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sweet-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "# warning뜬다\n",
    "# WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. \n",
    "# It will use generic GPU kernel as fallback when running on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-philip",
   "metadata": {},
   "source": [
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일해요. 하지만 LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야 해요.  \n",
    "  \n",
    "디코더의 출력층을 설계해볼게요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "trying-reputation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 41)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 41, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 41, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 41, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    1152000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 41, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9000)   2313000     lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,864,104\n",
      "Trainable params: 7,864,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-cardiff",
   "metadata": {},
   "source": [
    "디코더의 출력층에서는 Summary의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 해요. 그렇기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용하고 있어요.  \n",
    "  \n",
    "# Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "일반적인 seq2seq보다는 출력층 설계를 살짝 바꾼 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있다.   \n",
    "실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-publisher",
   "metadata": {},
   "source": [
    "깃허브에 공개되어져 있는 어텐션 함수를 다운로드  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "impaired-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-coordinate",
   "metadata": {},
   "source": [
    "## 디코더 출력층 수정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "minus-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 41)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 41, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 41, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 41, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    1152000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 41, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_4[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 9000)   4617000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,299,432\n",
      "Trainable params: 10,299,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (추가)어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "\n",
    "# (추가)인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# (추가)어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# (수정)디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-porter",
   "metadata": {},
   "source": [
    "위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고,  \n",
    "어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-import",
   "metadata": {},
   "source": [
    "## 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "mounted-pattern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "308/308 [==============================] - 103s 336ms/step - loss: 5.9399 - val_loss: 5.5168\n",
      "Epoch 2/100\n",
      "308/308 [==============================] - 102s 333ms/step - loss: 5.3273 - val_loss: 5.1111\n",
      "Epoch 3/100\n",
      "308/308 [==============================] - 105s 340ms/step - loss: 4.9623 - val_loss: 4.8192\n",
      "Epoch 4/100\n",
      "308/308 [==============================] - 104s 337ms/step - loss: 4.6821 - val_loss: 4.6112\n",
      "Epoch 5/100\n",
      "308/308 [==============================] - 104s 336ms/step - loss: 4.4545 - val_loss: 4.4454\n",
      "Epoch 6/100\n",
      "308/308 [==============================] - 104s 337ms/step - loss: 4.2629 - val_loss: 4.3106\n",
      "Epoch 7/100\n",
      "308/308 [==============================] - 104s 337ms/step - loss: 4.0990 - val_loss: 4.2014\n",
      "Epoch 8/100\n",
      "308/308 [==============================] - 102s 331ms/step - loss: 3.9604 - val_loss: 4.1258\n",
      "Epoch 9/100\n",
      "308/308 [==============================] - 103s 333ms/step - loss: 3.8405 - val_loss: 4.0723\n",
      "Epoch 10/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.7354 - val_loss: 4.0118\n",
      "Epoch 11/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.6412 - val_loss: 3.9571\n",
      "Epoch 12/100\n",
      "308/308 [==============================] - 105s 341ms/step - loss: 3.5560 - val_loss: 3.9231\n",
      "Epoch 13/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.4812 - val_loss: 3.8897\n",
      "Epoch 14/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.4108 - val_loss: 3.8609\n",
      "Epoch 15/100\n",
      "308/308 [==============================] - 104s 339ms/step - loss: 3.3502 - val_loss: 3.8418\n",
      "Epoch 16/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.2909 - val_loss: 3.8226\n",
      "Epoch 17/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.2338 - val_loss: 3.8106\n",
      "Epoch 18/100\n",
      "308/308 [==============================] - 104s 339ms/step - loss: 3.1829 - val_loss: 3.7997\n",
      "Epoch 19/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.1341 - val_loss: 3.7717\n",
      "Epoch 20/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.0878 - val_loss: 3.7609\n",
      "Epoch 21/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.0441 - val_loss: 3.7454\n",
      "Epoch 22/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 3.0020 - val_loss: 3.7430\n",
      "Epoch 23/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 2.9647 - val_loss: 3.7348\n",
      "Epoch 24/100\n",
      "308/308 [==============================] - 104s 337ms/step - loss: 2.9305 - val_loss: 3.7360\n",
      "Epoch 25/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 2.8948 - val_loss: 3.7251\n",
      "Epoch 26/100\n",
      "308/308 [==============================] - 104s 339ms/step - loss: 2.8601 - val_loss: 3.7309\n",
      "Epoch 27/100\n",
      "308/308 [==============================] - 104s 339ms/step - loss: 2.8291 - val_loss: 3.7199\n",
      "Epoch 28/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 2.8014 - val_loss: 3.7266\n",
      "Epoch 29/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 2.7723 - val_loss: 3.7178\n",
      "Epoch 30/100\n",
      "308/308 [==============================] - 104s 338ms/step - loss: 2.7472 - val_loss: 3.7285\n",
      "Epoch 31/100\n",
      "308/308 [==============================] - 105s 339ms/step - loss: 2.7203 - val_loss: 3.7197\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 얼리스탑핑 덕분에 23분 정도 걸림\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-values",
   "metadata": {},
   "source": [
    "## Loss의 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "spiritual-showcase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-courtesy",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-pearl",
   "metadata": {},
   "source": [
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "moving-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-gathering",
   "metadata": {},
   "source": [
    "seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 한다는 것, 알고 계시나요?  \n",
    "  \n",
    "훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한번에 비교할 수 있으므로, 인코더와 디코더를 엮은 통짜 모델 하나만 준비했습니다.  \n",
    "  \n",
    "그러나 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 합니다. 이때는 인코더 모델과 디코더 모델을 분리해서 설계합니다.  \n",
    "## 인코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "driven-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-parliament",
   "metadata": {},
   "source": [
    "## 출력층 설계 (어텐션 함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "automated-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-bargain",
   "metadata": {},
   "source": [
    "## (인퍼런스 단계) 단어 시퀀스 완성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "measured-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (head_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-pilot",
   "metadata": {},
   "source": [
    "# Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해보세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-frank",
   "metadata": {},
   "source": [
    "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 편하겠죠. \n",
    "주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어볼게요. 함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외시키고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외시키도록 만들거에요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "introductory-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "processed-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 기사\n",
      "원문 : fir filed self proclaimed critic kamaal khan allegedly making disrespectful comments lgbtq community video youtube channel uploaded video september day supreme court decriminalised homosexuality khan booked obscenity promoting communal disharmony passing statements aimed causing hatred classes \n",
      "실제 요약 : fir against krk over vulgar remarks against lgbtq community \n",
      "예측 요약 :  fir filed against salman for abusing hate speech on fb\n",
      "\n",
      "\n",
      "2 번째 기사\n",
      "원문 : former indian captain sourav ganguly said current captain virat kohli confidence faith former captain ms dhoni transformed year old career players made players broken faith show ganguly said dhoni far scored runs odis average \n",
      "실제 요약 : captain virat kohli has dhoni career ganguly \n",
      "예측 요약 :  kohli has become an team for kohli ganguly\n",
      "\n",
      "\n",
      "3 번째 기사\n",
      "원문 : united nations study revealed ozone layer shields earth cancer causing solar rays completely hole antarctic healing rate year study revealed study four yearly review montreal protocol banned man made gases damaging ozone layer \n",
      "실제 요약 : ozone layer will be completely by un study \n",
      "예측 요약 :  earth may be found in earth study\n",
      "\n",
      "\n",
      "4 번째 기사\n",
      "원문 : uk financial conduct authority fined state owned canara bank uk division breaching anti money laundering laws also prohibited bank accepting new deposits nearly five months regulator said control failures bank affected almost levels business governance structure including senior management \n",
      "실제 요약 : bank fined cr in uk for money laundering breaches \n",
      "예측 요약 :  uk fines uk bank over illegal\n",
      "\n",
      "\n",
      "5 번째 기사\n",
      "원문 : criticising kate middleton setting unrealistic expectations women appear certain way post pregnancy actress wrote open letter seven hours post delivery kate stood front cameras looking stylish hide pain bodies splitting breasts leaking hormones look beautiful stylish show added \n",
      "실제 요약 : hrs post delivery kate stood there looking \n",
      "예측 요약 :  jennifer slams jennifer for women jennifer lawrence starrer\n",
      "\n",
      "\n",
      "6 번째 기사\n",
      "원문 : members family found dead delhi burari sunday police said recovered handwritten notes point towards spiritual practices whole family notes strong similarity manner mouths eyes etc deceased tied taped police added \n",
      "실제 요약 : notes suggest spiritual to death of of family police \n",
      "예측 요약 :  burari family found dead at house in delhi\n",
      "\n",
      "\n",
      "7 번째 기사\n",
      "원문 : shiv sena allied bjp led maharashtra government planned july back farmers loan waiver demands party members assemble outside district cooperative banks maharashtra beating drums protest aimed making banks disclose list farmers government loan waiver scheme \n",
      "실제 요약 : shiv sena plans protest for farm loan waiver \n",
      "예측 요약 :  maha govt proposes loan waiver for farmers shiv sena\n",
      "\n",
      "\n",
      "8 번째 기사\n",
      "원문 : filmmaker anurag kashyap said woman controlling men minds college friends would tell ladki agar bhi toh hai added kashyap said across board across globe taught us works level \n",
      "실제 요약 : friends said hold girl hand even if she refuses kashyap \n",
      "예측 요약 :  woman should be shown as director anurag\n",
      "\n",
      "\n",
      "9 번째 기사\n",
      "원문 : us president donald trump wednesday signed right try bill gives terminally ill patients right seek experimental treatments approved government patients seeking access experimental drugs longer need permission food drug administration require approval physician drug manufacturer \n",
      "실제 요약 : us allows ill patients to try drugs \n",
      "예측 요약 :  trump signs bill of mental mental disorder\n",
      "\n",
      "\n",
      "10 번째 기사\n",
      "원문 : carl year old american cyclist stripped cycling title world record violated anti doping laws oldest participant event men sprint title july claimed contaminated meat reason tested positive banned substance \n",
      "실제 요약 : yr old cyclist stripped of record post failed drug test \n",
      "예측 요약 :  yr old girl becomes world youngest champ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 금방 끝남\n",
    "for i in range(0, 10):\n",
    "    print(i+1,'번째 기사')\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-evaluation",
   "metadata": {},
   "source": [
    "# Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요.  \n",
    "  \n",
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-cabinet",
   "metadata": {},
   "source": [
    "## 패키지 설치\n",
    "```\n",
    "! pip install summa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "laden-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "text = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "present-bible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        saurav kant alumnus upgrad iiit pg program mac...\n",
      "1        kunal shah credit card bill payment platform c...\n",
      "2        new zealand defeated india wickets fourth odi ...\n",
      "3        aegon life iterm insurance plan customers enjo...\n",
      "4        speaking sexual harassment allegations rajkuma...\n",
      "                               ...                        \n",
      "98396    crpf jawan tuesday axed death sharp edged weap...\n",
      "98397    uff yeh first song sonakshi sinha starrer upco...\n",
      "98398    according reports new version science fiction ...\n",
      "98399    new music video shows rapper snoop dogg aiming...\n",
      "98400    madhesi morcha alliance seven political partie...\n",
      "Name: text, Length: 98360, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 일부 출력으로 확인하기\n",
    "print(text[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "southern-spanish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-photographer",
   "metadata": {},
   "source": [
    "타입이 'str'이 아니라 'series'가 나와서 Summa의 summarize()를 이용할 수가 없다  \n",
    "-> 다른 방법으로 데이터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "oriental-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data_news = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "traditional-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data_news.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data_news)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-contribution",
   "metadata": {},
   "source": [
    "하나의 text로 인자 값들 확인 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "declared-physics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_0 = data_news['text'][0]\n",
    "text_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-management",
   "metadata": {},
   "source": [
    "## summarize 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-going",
   "metadata": {},
   "source": [
    "Summa의 summarize()의 인자로 사용되는 값들에 대해서 알아볼게요.\n",
    "\n",
    ">text (str) : 요약할 테스트.  \n",
    "ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값   \n",
    "words (int or None, optional) – 출력에 포함할 단어 수.  \n",
    "만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.    \n",
    "split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환   \n",
    "  \n",
    "Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행해요.   \n",
    "그렇기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있어요. 비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여볼게요. 원문의 0.005%만을 출력해도록 설정했어요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "compliant-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike.\n",
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "\n",
    "print(summarizer.summarize(text_0, ratio=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "internal-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike.\n",
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "print(summarizer.summarize(text_0, ratio=0.67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "robust-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "print(summarizer.summarize(text_0, ratio=0.65))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-iraqi",
   "metadata": {},
   "source": [
    "## 추출적 요약과 Orginal 요약 비교해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "owned-berry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :  upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "추출적 요약 :  upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "head_0 = data_news['headlines'][0]\n",
    "print(\"Original : \",head_0)\n",
    "print('추출적 요약 : ',summarizer.summarize(text_0, ratio=0.65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-small",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-nashville",
   "metadata": {},
   "source": [
    "# Extractive 요약 & Abstractive 요약 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-spelling",
   "metadata": {},
   "source": [
    "비교를 하기 위해서 같은 test data에 있는 기사 중에서 같은 기사를 골라서 요약 해야 하는데,  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-carol",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "willing-franklin",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "favorite-diving",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "textile-desktop",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "piano-reynolds",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fatty-speech",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-exhaust",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nominated-packaging",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "limiting-while",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "central-progress",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-future",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-ready",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "published-gather",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "italic-drama",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "affecting-copyright",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fossil-trader",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-armor",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lasting-apparel",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "consistent-produce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "junior-board",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sixth-might",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "banned-fourth",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "western-output",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "express-motivation",
   "metadata": {},
   "source": [
    "# 루브릭  \n",
    "평가문항\t상세기준\n",
    "1. Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.  \n",
    "분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.  \n",
    "\n",
    "  \n",
    "2. 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.  \n",
    "모델학습이 안정적으로 수렴되었음을 그래프를 통해 확인하였으며, 실제 요약문과 유사한 요약문장을 얻을 수 있었다.  \n",
    "  \n",
    "\n",
    "3. Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.    \n",
    "두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교분석 결과를 제시하였다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-jacket",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rising-bones",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "declared-korea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "associate-manual",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "functioning-comparison",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "motivated-punch",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "golden-montreal",
   "metadata": {},
   "source": [
    "# 필수 보충"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-singles",
   "metadata": {},
   "source": [
    "lamda 함수 이해 안 감    \n",
    "```\n",
    "# 우리는 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제할게요.\n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-worth",
   "metadata": {},
   "source": [
    "API 이해하기  \n",
    "Rapid API  \n",
    "https://moonspam.github.io/What-is-an-API/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "411.771px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
