{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collect-squad",
   "metadata": {},
   "source": [
    "# 9-1\n",
    "학습 전제  \n",
    "정형 데이터를 활용해 EDA와 간단한 분류, 회귀 문제를 해결해본 적이 있다.  \n",
    "numpy, pandas, matplotlib을 활용해 정형 데이터를 자유자재로 다룰 수 있다.  \n",
    "정형 데이터를 활용해 다양한 모델을 학습시켜보고, 예측 결과를 도출하는 것까지의 과정을 코드로 진행할 수 있다.  \n",
    "  \n",
    "학습 목표  \n",
    "데이터 사이언스 관련 최대 커뮤니티인 캐글의 경진대회에 직접 참여해서 문제를 해결해본다.  \n",
    "캐글에서 데이터를 내려받는 것으로부터 시작해서, 로컬 서버에서 자유롭게 다루어보며 문제 해결을 위한 고민을 해본다.  \n",
    "앙상블 기법의 개념과 강점을 이해하고, 여러 모델의 예측 결과를 Averaging 한 최종 결과로 캐글에 제출해본다.  \n",
    "하이퍼 파라미터 튜닝의 필요성과 의미를 이해하고, Grid Search, Random Search 등의 기법을 알아본다.  \n",
    "Grid Search 기법을 활용해서 직접 하이퍼 파라미터 튜닝 실험을 해보고, 모델의 성능을 최대한 끌어올려본다.  \n",
    "  \n",
    "목차  \n",
    "대회의 시작: 참가 규칙과 데이터, 평가 기준 살펴보기  \n",
    "자 그럼, 일단 제출하고 시작해! Baseline은 여기 있으니까!  \n",
    "랭킹을 올리고 싶다면? 최적의 모델을 찾아서, 하이퍼 파라미터 튜닝  \n",
    "프로젝트: This is your playground! Leaderboard를 정복해주세요!  \n",
    "  \n",
    "준비물  \n",
    "회귀 모델을 구현하는 데에 사용하는 xgboost와 lightgbm 라이브러리와, 결측 데이터를 확인하는 missingno 라이브러리가 필요합니다.  \n",
    "```\n",
    "$ conda install -c conda-forge xgboost\n",
    "$ conda install -c conda-forge lightgbm\n",
    "$ conda install -c conda-forge missingno\n",
    "$ pip install scikit-learn==0.23.0\n",
    "$ mkdir -p ~/aiffel/kaggle_kakr_housing\n",
    "```\n",
    "  \n",
    "# 9-2. 대회의 시작 (1) 참가 규칙, 평가 기준 살펴보기  \n",
    "**A. Description, 대회 소개**  \n",
    "참여방법   \n",
    "https://bit.ly/2UuQvtU  \n",
    "  \n",
    "**B. Evaluation, 점수 평가 기준**  \n",
    "회귀문제  \n",
    "  \n",
    "**C. Prize, 상품**  \n",
    "etc  \n",
    ".  \n",
    ".  \n",
    ".  \n",
    ".  \n",
    "# 9-4. 일단 제출하고 시작해! Baseline 모델 (1) Baseline 셋팅하기  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distant-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "urban-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얍💢\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('얍💢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj35/aiffel/kaggle_kakr_housing/data/train.csv\n",
      "/home/aiffel-dj35/aiffel/kaggle_kakr_housing/data/test.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "sub_data_path = join(data_dir, 'test.csv')      # 테스트, 즉 submission 시 사용할 데이터 경로\n",
    "\n",
    "print(train_data_path)\n",
    "print(sub_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-coast",
   "metadata": {},
   "source": [
    "1. ID : 집을 구분하는 번호\n",
    "2. date : 집을 구매한 날짜\n",
    "3. price : 타겟 변수인 집의 가격\n",
    "4. bedrooms : 침실의 수\n",
    "5. bathrooms : 침실당 화장실 개수\n",
    "6. sqft_living : 주거 공간의 평방 피트\n",
    "7. sqft_lot : 부지의 평방 피트\n",
    "8. floors : 집의 층수\n",
    "9. waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
    "10. view : 집이 얼마나 좋아 보이는지의 정도\n",
    "11. condition : 집의 전반적인 상태\n",
    "12. grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
    "13. sqft_above : 지하실을 제외한 평방 피트\n",
    "14. sqft_basement : 지하실의 평방 피트\n",
    "15. yr_built : 집을 지은 년도\n",
    "16. yr_renovated : 집을 재건축한 년도\n",
    "17. zipcode : 우편번호\n",
    "18. lat : 위도\n",
    "19. long : 경도\n",
    "20. sqft_living15 : 2015년 기준 주거 공간의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)\n",
    "21. sqft_lot15 : 2015년 기준 부지의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)\n",
    "print('train data dim : {}'.format(data.shape))\n",
    "print('sub data dim : {}'.format(sub.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-raise",
   "metadata": {},
   "source": [
    "학습 데이터는 약 1만 5천 개, 테스트 데이터는 약 6천 개로 이루어져 있군요.\n",
    "테스트 데이터는 물론 우리가 맞추어야 할 집의 가격, price가 없기 때문에 컬럼이 하나 적습니다.\n",
    "\n",
    "✓ 학습 데이터에서 라벨 제거하기\n",
    "price 컬럼은 따로 y라는 변수에 저장한 후 해당 컬럼은 지워줍니다.\n",
    "\n",
    "참고: w3schools - python del keyword\n",
    "참고로 데이터 분석 과정에서 칼럼을 없애고 싶다면 pandas.DataFrame.drop도 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "del data['price']\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-relation",
   "metadata": {},
   "source": [
    "✓ 학습 데이터와 테스트 데이터 합치기\n",
    "모델을 학습시키기 전에, 전체 데이터에 대해 탐색해보기 위해 두 데이터를 pd.concat으로 합쳐봅니다.\n",
    "\n",
    "물론, 모델 학습을 진행할 때에는 다시 분리해서 사용해야 하기 때문에 데이터를 합치기 전 train_len에 training data의 개수를 저장해서 추후에 학습데이터만 불러올 수 있는 인덱스로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(data)\n",
    "data = pd.concat((data, sub), axis=0)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "✓ 간단한 전처리\n",
    "빈 데이터와 전체 데이터의 분포를 확인하는 전처리 작업입니다.\n",
    "결측치, 즉 빈 데이터가 있는지는 위에서 설치했던 missingno 라이브러리를 사용해서 확인하는군요.\n",
    "\n",
    "원본 노트북에서는 다음과 같이 설명합니다.\n",
    "\n",
    "각 변수들에 대해 결측 유무를 확인하고, 분포를 확인해보면서 간단하게 전처리를 하겠습니다.\n",
    "먼저 데이터에 결측치가 있는지를 확인하겠습니다.\n",
    "missingno 라이브러리의 matrix 함수를 사용하면, 데이터의 결측 상태를 시각화를 통해 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-condition",
   "metadata": {},
   "source": [
    "위에 출력된 것은 data라는 DataFrame을 매트릭스 모양 그대로 시각화한 것입니다. 만약 특정 row, col에 NaN이라는 결측치가 있었다면 해당 부분이 하얗게 나옵니다. 결측치가 없다면 매트릭스 전체가 까맣게 나올 겁니다. 실제로 그렇게 나왔나요??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-bolivia",
   "metadata": {},
   "source": [
    "✓ id, date 변수 정리\n",
    "필요 없는 id 컬럼을 제거합니다. 나중에 예측 결과를 제출할 때를 대비하여 sub_id 변수에 id 칼럼을 저장해두고 지우도록 하겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date'].apply(lambda x : str(x[:6])) # 연/월 데이터만 사용하기 위해\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9, 2, figsize=(12, 50))   # 가로스크롤 때문에 그래프 확인이 불편하다면 figsize의 x값을 조절해 보세요. \n",
    "\n",
    "# id 변수(count==0인 경우)는 제외하고 분포를 확인합니다.\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-feeding",
   "metadata": {},
   "source": [
    "그래프의 분포를 보면 어떤 처리를 해주면 좋을지 떠올릴 수 있습니다.\n",
    "\n",
    "위 그래프 중에서는 bedrooms, sqft_living, sqft_lot, sqft_above, sqft_basement 변수가 한쪽으로 치우친 경향을 보이는군요.  \n",
    "이렇게 한 쪽으로 치우친 분포의 경우에는 로그 변환(log-scaling)을 통해 데이터 분포를 정규분포에 가깝게 만들 수 있습니다. 자세한 이유는 아래에서 다시 다루고, 우선 결과부터 살펴봅시다.  \n",
    "\n",
    "아래와 같이 치우친 컬럼들을 skew_columns 리스트 안에 담고, 모두 np.log1p()를 활용해서 로그 변환을 해주도록 하겠습니다. numpy.log1p() 함수는 입력 배열의 각 요소에 대해 자연로그 log(1 + x)을 반환해 주는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)\n",
    "\n",
    "print('얍💢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환 후\n",
    "fig, ax = plt.subplots(3, 2, figsize=(12, 15))\n",
    "\n",
    "count = 0\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        if count == 5:\n",
    "            break\n",
    "        sns.kdeplot(data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-academy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-courage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-petite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-delaware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-minnesota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-chuck",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-berry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-surname",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-update",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-former",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-nirvana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-transformation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-earth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-latex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-stocks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-today",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-flush",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
